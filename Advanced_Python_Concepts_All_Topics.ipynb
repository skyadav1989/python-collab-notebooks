{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyadav1989/python-collab-notebooks/blob/main/Advanced_Python_Concepts_All_Topics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4FEH0StGV9m"
      },
      "source": [
        "# ğŸ Advanced Python Concepts\n",
        "### A Complete Reference with Real-World Examples\n",
        "\n",
        "> **21 topics** Â· Production-grade code Â· Google Colab ready\n",
        "\n",
        "---\n",
        "\n",
        "| # | Topic | # | Topic |\n",
        "|---|-------|---|-------|\n",
        "| 1 | Metaclasses | 12 | `__slots__` |\n",
        "| 2 | Descriptors | 13 | Abstract Base Classes |\n",
        "| 3 | Context Managers | 14 | Monkey Patching |\n",
        "| 4 | Decorators | 15 | Function Closures |\n",
        "| 5 | Generators & Coroutines | 16 | Introspection & Reflection |\n",
        "| 6 | Asyncio (async/await) | 17 | Dynamic Attribute Access |\n",
        "| 7 | Multithreading | 18 | Data Model & Dunder Methods |\n",
        "| 8 | Multiprocessing | 19 | C Extensions (Cython/CFFI) |\n",
        "| 9 | Global Interpreter Lock | 20 | Bytecode & Python VM |\n",
        "| 10 | Memory Management & GC | 21 | Profiling & Performance |\n",
        "| 11 | Weak References | | |\n",
        "\n",
        "---\n"
      ],
      "id": "m4FEH0StGV9m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "hfy0tLIYGV9o"
      },
      "outputs": [],
      "source": [
        "# âœ… Run this first â€” standard library only, no installs needed\n",
        "import sys\n",
        "print(f\"Python {sys.version}\")\n",
        "print(\"All cells use stdlib only â€” no pip installs required!\")\n"
      ],
      "id": "hfy0tLIYGV9o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0zeh86MGV9p"
      },
      "source": [
        "---\n",
        "## ğŸ—ï¸ Topic 1: Metaclasses\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "I0zeh86MGV9p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJS2H4H_GV9p"
      },
      "source": [
        "### What is it?\n",
        "A **metaclass** is the *class of a class*. Just as an instance is built by its class,\n",
        "a class is built by its metaclass. By default every Python class uses `type` as its metaclass.\n",
        "\n",
        "When Python executes a `class` statement it calls `type.__new__(mcs, name, bases, namespace)`.\n",
        "Overriding this lets you inspect or modify the class **before it ever exists**.\n",
        "\n",
        "### Real-World Use Case\n",
        "> **Django ORM** â€” model fields are discovered automatically, subclasses are registered\n",
        "> in an internal registry, and database table names are derived â€” all without the developer\n",
        "> calling any registration function explicitly.\n",
        "\n",
        "### How it works\n",
        "```\n",
        "User defines class  â”€â”€â–º  Python calls metaclass.__new__()  â”€â”€â–º  class object created\n",
        "```\n"
      ],
      "id": "hJS2H4H_GV9p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "UTcVoSQLGV9q"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Example: Auto-registering API endpoint router â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class EndpointMeta(type):\n",
        "    \"\"\"Metaclass that auto-populates a URL registry.\"\"\"\n",
        "    registry = {}\n",
        "\n",
        "    def __new__(mcs, name, bases, namespace):\n",
        "        cls = super().__new__(mcs, name, bases, namespace)\n",
        "        route = namespace.get('route')\n",
        "        if route:                          # only register concrete endpoints\n",
        "            mcs.registry[route] = cls\n",
        "        return cls\n",
        "\n",
        "\n",
        "class BaseEndpoint(metaclass=EndpointMeta):\n",
        "    \"\"\"All API endpoints inherit from this.\"\"\"\n",
        "\n",
        "\n",
        "class UserEndpoint(BaseEndpoint):\n",
        "    route = '/users'\n",
        "    def handle(self, request): return {'users': ['Alice', 'Bob']}\n",
        "\n",
        "\n",
        "class ProductEndpoint(BaseEndpoint):\n",
        "    route = '/products'\n",
        "    def handle(self, request): return {'products': ['Widget', 'Gadget']}\n",
        "\n",
        "\n",
        "class OrderEndpoint(BaseEndpoint):\n",
        "    route = '/orders'\n",
        "    def handle(self, request): return {'orders': [101, 102]}\n",
        "\n",
        "\n",
        "# â”€â”€ Router is auto-populated â€” zero manual registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Registered routes:\", list(EndpointMeta.registry.keys()))\n",
        "\n",
        "def dispatch(route, request={}):\n",
        "    handler_cls = EndpointMeta.registry.get(route)\n",
        "    if handler_cls:\n",
        "        return handler_cls().handle(request)\n",
        "    return {'error': '404 Not Found'}\n",
        "\n",
        "print(dispatch('/users'))\n",
        "print(dispatch('/products'))\n",
        "print(dispatch('/missing'))\n"
      ],
      "id": "UTcVoSQLGV9q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDaYEhy6GV9r"
      },
      "source": [
        "### Key Insight\n",
        "Every time a subclass of `BaseEndpoint` is **defined**, `EndpointMeta.__new__` fires\n",
        "and populates the registry â€” no decorator, no manual call needed.\n",
        "\n",
        "### When to use\n",
        "- Framework-level concerns (ORM field discovery, plugin registries, interface enforcement)\n",
        "- For simpler needs prefer `__init_subclass__` or class decorators â€” less cognitive load\n"
      ],
      "id": "eDaYEhy6GV9r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZbb9qCHGV9r"
      },
      "source": [
        "---\n",
        "## ğŸ”Œ Topic 2: Descriptors\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "nZbb9qCHGV9r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilmx_v9tGV9r"
      },
      "source": [
        "### What is it?\n",
        "A **descriptor** is any object that defines `__get__`, `__set__`, or `__delete__`.\n",
        "Descriptors are the engine behind `@property`, `classmethod`, `staticmethod`, and ORM fields.\n",
        "\n",
        "| Type | Methods | Priority |\n",
        "|------|---------|----------|\n",
        "| **Data descriptor** | `__get__` + `__set__` or `__delete__` | Beats instance `__dict__` |\n",
        "| **Non-data descriptor** | `__get__` only | Overridden by instance attributes |\n",
        "\n",
        "### Real-World Use Case\n",
        "> **Django model fields** â€” `CharField`, `IntegerField` etc. are descriptors that\n",
        "> intercept attribute access to handle validation, lazy loading, and serialisation.\n"
      ],
      "id": "ilmx_v9tGV9r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Ggb8Q-u6GV9s"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Example: Validated field descriptor (mini-Django) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class TypedField:\n",
        "    \"\"\"Descriptor that enforces a type and optional numeric range.\"\"\"\n",
        "\n",
        "    def __init__(self, field_type, min_val=None, max_val=None):\n",
        "        self.field_type = field_type\n",
        "        self.min_val    = min_val\n",
        "        self.max_val    = max_val\n",
        "        self.private_name = None   # set by __set_name__\n",
        "\n",
        "    def __set_name__(self, owner, name):\n",
        "        \"\"\"Called automatically when the owning class is created.\"\"\"\n",
        "        self.private_name = f'_{name}'\n",
        "\n",
        "    def __get__(self, obj, objtype=None):\n",
        "        if obj is None:            # accessed on the class itself\n",
        "            return self\n",
        "        return getattr(obj, self.private_name, None)\n",
        "\n",
        "    def __set__(self, obj, value):\n",
        "        if not isinstance(value, self.field_type):\n",
        "            raise TypeError(\n",
        "                f'Expected {self.field_type.__name__}, got {type(value).__name__}'\n",
        "            )\n",
        "        if self.min_val is not None and value < self.min_val:\n",
        "            raise ValueError(f'Value {value!r} is below minimum {self.min_val}')\n",
        "        if self.max_val is not None and value > self.max_val:\n",
        "            raise ValueError(f'Value {value!r} exceeds maximum {self.max_val}')\n",
        "        setattr(obj, self.private_name, value)\n",
        "\n",
        "\n",
        "class Product:\n",
        "    name  = TypedField(str)\n",
        "    price = TypedField(float, min_val=0.0)\n",
        "    stock = TypedField(int,   min_val=0, max_val=10_000)\n",
        "\n",
        "    def __init__(self, name, price, stock):\n",
        "        self.name  = name\n",
        "        self.price = price\n",
        "        self.stock = stock\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Product({self.name!r}, ${self.price}, qty={self.stock})'\n",
        "\n",
        "\n",
        "# â”€â”€ Happy path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "p = Product('Widget', 9.99, 100)\n",
        "print(p)\n",
        "print('Price:', p.price)\n",
        "\n",
        "# â”€â”€ Validation errors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for attempt in [\n",
        "    lambda: Product('Widget', -1.0,  100),   # negative price\n",
        "    lambda: Product(42,        9.99, 100),   # wrong type for name\n",
        "    lambda: Product('Widget',  9.99, 99999), # stock too high\n",
        "]:\n",
        "    try:\n",
        "        attempt()\n",
        "    except (TypeError, ValueError) as e:\n",
        "        print(f'  âœ— {type(e).__name__}: {e}')\n"
      ],
      "id": "Ggb8Q-u6GV9s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swdUll2GV9s"
      },
      "source": [
        "---\n",
        "## ğŸ”’ Topic 3: Context Managers\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "1swdUll2GV9s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1VwwO-4GV9s"
      },
      "source": [
        "### What is it?\n",
        "Context managers manage resources by **guaranteeing setup and teardown** via the `with`\n",
        "statement, even if an exception occurs. They implement `__enter__` and `__exit__`\n",
        "(class-based) or use `@contextlib.contextmanager` (generator-based).\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Database transactions Â· File locking Â· Temporary directories Â· Mock patching in tests\n",
        "> Â· Distributed transaction management Â· Timer context managers for benchmarking\n",
        "\n",
        "### Protocol\n",
        "```python\n",
        "with SomeContextManager() as value:\n",
        "    # __enter__ ran, value returned\n",
        "    ...\n",
        "# __exit__ always runs here â€” even after exceptions\n",
        "```\n"
      ],
      "id": "u1VwwO-4GV9s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "do1E7de-GV9t"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# â”€â”€ Class-based approach â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class DatabaseConnection:\n",
        "    \"\"\"Context manager that wraps a SQLite connection in a transaction.\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.conn    = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        self.conn.execute('BEGIN')\n",
        "        print('  [DB] Transaction started')\n",
        "        return self.conn.cursor()\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        if exc_type is None:\n",
        "            self.conn.commit()\n",
        "            print('  [DB] âœ“ Committed')\n",
        "        else:\n",
        "            self.conn.rollback()\n",
        "            print(f'  [DB] âœ— Rolled back â€” {exc_type.__name__}: {exc_val}')\n",
        "        self.conn.close()\n",
        "        return False   # don't suppress exceptions\n",
        "\n",
        "\n",
        "# â”€â”€ Generator-based approach with contextlib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "@contextmanager\n",
        "def managed_transaction(db_path: str):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    try:\n",
        "        conn.execute('BEGIN')\n",
        "        yield conn.cursor()\n",
        "        conn.commit()\n",
        "        print('  [CTX] âœ“ Committed')\n",
        "    except Exception:\n",
        "        conn.rollback()\n",
        "        print('  [CTX] âœ— Rolled back')\n",
        "        raise\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "# â”€â”€ Demo: successful transaction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"=== Successful transaction ===\")\n",
        "with DatabaseConnection(':memory:') as cur:\n",
        "    cur.execute('CREATE TABLE items (id INTEGER, name TEXT)')\n",
        "    cur.execute(\"INSERT INTO items VALUES (1, 'Alpha')\")\n",
        "    cur.execute(\"INSERT INTO items VALUES (2, 'Beta')\")\n",
        "\n",
        "# â”€â”€ Demo: failed transaction (auto-rollback) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n=== Failed transaction (auto-rollback) ===\")\n",
        "try:\n",
        "    with DatabaseConnection(':memory:') as cur:\n",
        "        cur.execute('CREATE TABLE x (id INTEGER)')\n",
        "        cur.execute(\"INSERT INTO x VALUES (1)\")\n",
        "        raise RuntimeError(\"Simulated mid-transaction failure!\")\n",
        "except RuntimeError:\n",
        "    pass\n",
        "\n",
        "# â”€â”€ Demo: contextmanager version â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n=== contextmanager version ===\")\n",
        "with managed_transaction(':memory:') as cur:\n",
        "    cur.execute('CREATE TABLE items (id INTEGER, name TEXT)')\n",
        "    cur.execute(\"INSERT INTO items VALUES (1, 'Gamma')\")\n"
      ],
      "id": "do1E7de-GV9t"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gkii_U9GV9t"
      },
      "source": [
        "---\n",
        "## ğŸ¨ Topic 4: Decorators\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "1Gkii_U9GV9t"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf422MwkGV9t"
      },
      "source": [
        "### What is it?\n",
        "A **decorator** is a callable that takes a function (or class) as input and returns a\n",
        "replacement. They add cross-cutting concerns â€” caching, logging, rate-limiting, auth â€”\n",
        "**without modifying** the original function.\n",
        "\n",
        "### Real-World Use Cases\n",
        "> `@app.route` in Flask Â· `@router.get` in FastAPI Â· `@login_required` in Django\n",
        "> Â· `@retry` in microservices Â· `@cache` for memoisation Â· `@pytest.fixture`\n",
        "\n",
        "### Anatomy\n",
        "```\n",
        "@decorator          â† sugar for:  func = decorator(func)\n",
        "def func(): ...\n",
        "```\n"
      ],
      "id": "Pf422MwkGV9t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "7vc1pq_lGV9t"
      },
      "outputs": [],
      "source": [
        "import time, functools, logging\n",
        "\n",
        "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# â”€â”€ 1. Retry with exponential back-off â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def retry(max_attempts=3, delay=0.1, backoff=2.0, exceptions=(Exception,)):\n",
        "    \"\"\"Decorator factory: retries a function on transient failures.\"\"\"\n",
        "    def decorator(func):\n",
        "        @functools.wraps(func)   # preserves __name__, __doc__, __annotations__\n",
        "        def wrapper(*args, **kwargs):\n",
        "            wait = delay\n",
        "            for attempt in range(1, max_attempts + 1):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except exceptions as exc:\n",
        "                    if attempt == max_attempts:\n",
        "                        raise\n",
        "                    print(f'  âš  Attempt {attempt}/{max_attempts} failed ({exc}). '\n",
        "                          f'Retrying in {wait:.2f}s...')\n",
        "                    time.sleep(wait)\n",
        "                    wait *= backoff\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "\n",
        "# â”€â”€ 2. Timing decorator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def timeit_dec(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        t0     = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        elapsed = time.perf_counter() - t0\n",
        "        print(f'  â± {func.__name__}() took {elapsed*1000:.2f}ms')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "# â”€â”€ Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "_call_count = 0\n",
        "\n",
        "@retry(max_attempts=3, delay=0.05, backoff=2, exceptions=(ConnectionError,))\n",
        "@timeit_dec\n",
        "def fetch_user_data(user_id: int) -> dict:\n",
        "    \"\"\"Simulates a flaky API call that succeeds on the 3rd attempt.\"\"\"\n",
        "    global _call_count\n",
        "    _call_count += 1\n",
        "    if _call_count < 3:\n",
        "        raise ConnectionError(f'Network blip #{_call_count}')\n",
        "    return {'id': user_id, 'name': 'Alice', 'email': 'alice@example.com'}\n",
        "\n",
        "\n",
        "print(\"Fetching user data (will retry twice)...\")\n",
        "result = fetch_user_data(42)\n",
        "print(f\"  âœ“ Result: {result}\")\n",
        "\n",
        "# â”€â”€ functools.wraps preserves metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"\\n  Function name preserved: {fetch_user_data.__name__!r}\")\n",
        "print(f\"  Docstring preserved:     {fetch_user_data.__doc__!r}\")\n"
      ],
      "id": "7vc1pq_lGV9t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "cqUF1pcHGV9u"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Bonus: Class-based decorator (stateful) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class RateLimit:\n",
        "    \"\"\"Decorator that limits how often a function can be called.\"\"\"\n",
        "\n",
        "    def __init__(self, calls_per_second: float):\n",
        "        self.min_interval = 1.0 / calls_per_second\n",
        "        self.last_called  = 0.0\n",
        "\n",
        "    def __call__(self, func):\n",
        "        @functools.wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            now = time.monotonic()\n",
        "            wait_time = self.min_interval - (now - self.last_called)\n",
        "            if wait_time > 0:\n",
        "                time.sleep(wait_time)\n",
        "            self.last_called = time.monotonic()\n",
        "            return func(*args, **kwargs)\n",
        "        return wrapper\n",
        "\n",
        "\n",
        "@RateLimit(calls_per_second=5)   # max 5 calls per second\n",
        "def send_notification(msg: str):\n",
        "    print(f'  ğŸ“¢ Sent: {msg}')\n",
        "\n",
        "\n",
        "print(\"Sending 3 notifications (rate limited to 5/sec):\")\n",
        "for i in range(3):\n",
        "    send_notification(f'Alert #{i+1}')\n"
      ],
      "id": "cqUF1pcHGV9u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMcL8rW_GV9u"
      },
      "source": [
        "---\n",
        "## âš™ï¸ Topic 5: Generators & Coroutines\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "VMcL8rW_GV9u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo6EWzMOGV9u"
      },
      "source": [
        "### What is it?\n",
        "**Generators** are functions that `yield` values one at a time, suspending execution\n",
        "between calls â€” enabling **lazy evaluation** of arbitrarily large sequences.\n",
        "\n",
        "**Coroutines** extend generators to support bidirectional data flow via `send()`.\n",
        "\n",
        "### Why it matters\n",
        "```python\n",
        "# âŒ Loads 10GB into RAM first\n",
        "data = [process(row) for row in read_all_rows()]\n",
        "\n",
        "# âœ… Processes one row at a time â€” O(1) memory\n",
        "data = (process(row) for row in stream_rows())\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Streaming ETL pipelines Â· Infinite data streams Â· Log file processing\n",
        "> Â· Database cursor iteration Â· Cooperative multitasking\n"
      ],
      "id": "Bo6EWzMOGV9u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "_ACcrDOYGV9v"
      },
      "outputs": [],
      "source": [
        "import io, csv\n",
        "from typing import Iterator, Dict\n",
        "\n",
        "# â”€â”€ Simulated large dataset (in-memory for demo) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "SAMPLE_CSV = \"\"\"id,name,price,category\n",
        "1,Widget A,9.99,tools\n",
        "2,Gadget B,invalid,electronics\n",
        "3,Widget C,24.50,tools\n",
        "4,Gadget D,15.00,electronics\n",
        "5,,8.75,tools\n",
        "6,Widget E,33.20,tools\n",
        "7,Gadget F,12.00,electronics\n",
        "\"\"\"\n",
        "\n",
        "# â”€â”€ Generator pipeline stages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def read_rows(csv_text: str) -> Iterator[Dict]:\n",
        "    \"\"\"Stage 1: yield one dict per CSV row â€” never loads the whole file.\"\"\"\n",
        "    reader = csv.DictReader(io.StringIO(csv_text))\n",
        "    for row in reader:\n",
        "        yield row   # suspend here; resume when caller asks for next value\n",
        "\n",
        "\n",
        "def parse_and_validate(rows: Iterator) -> Iterator[Dict]:\n",
        "    \"\"\"Stage 2: type-coerce and skip malformed rows.\"\"\"\n",
        "    for row in rows:\n",
        "        try:\n",
        "            if not row.get('name', '').strip():\n",
        "                print(f'  âš  Skipping row {row[\"id\"]}: missing name')\n",
        "                continue\n",
        "            yield {\n",
        "                'id':       int(row['id']),\n",
        "                'name':     row['name'].strip(),\n",
        "                'price':    float(row['price']),\n",
        "                'category': row['category'],\n",
        "            }\n",
        "        except (ValueError, KeyError) as e:\n",
        "            print(f'  âš  Skipping malformed row {row.get(\"id\",\"?\")}: {e}')\n",
        "\n",
        "\n",
        "def apply_discount(rows: Iterator, pct: float) -> Iterator[Dict]:\n",
        "    \"\"\"Stage 3: transform prices.\"\"\"\n",
        "    for row in rows:\n",
        "        row['price'] = round(row['price'] * (1 - pct), 2)\n",
        "        row['discounted'] = True\n",
        "        yield row\n",
        "\n",
        "\n",
        "def filter_by_category(rows: Iterator, category: str) -> Iterator[Dict]:\n",
        "    \"\"\"Stage 4: filter.\"\"\"\n",
        "    for row in rows:\n",
        "        if row['category'] == category:\n",
        "            yield row\n",
        "\n",
        "\n",
        "def batch(rows: Iterator, size: int) -> Iterator[list]:\n",
        "    \"\"\"Stage 5: accumulate into fixed-size chunks for bulk DB inserts.\"\"\"\n",
        "    chunk = []\n",
        "    for row in rows:\n",
        "        chunk.append(row)\n",
        "        if len(chunk) == size:\n",
        "            yield chunk\n",
        "            chunk = []\n",
        "    if chunk:\n",
        "        yield chunk\n",
        "\n",
        "\n",
        "# â”€â”€ Compose the lazy pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pipeline = batch(\n",
        "    filter_by_category(\n",
        "        apply_discount(\n",
        "            parse_and_validate(\n",
        "                read_rows(SAMPLE_CSV)\n",
        "            ),\n",
        "            pct=0.10\n",
        "        ),\n",
        "        category='tools'\n",
        "    ),\n",
        "    size=2\n",
        ")\n",
        "\n",
        "print(\"=== Processing pipeline output ===\")\n",
        "for i, chunk in enumerate(pipeline, 1):\n",
        "    print(f\"  Batch {i}: {chunk}\")\n"
      ],
      "id": "_ACcrDOYGV9v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "pm0XFwzDGV9w"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Coroutine with send() â€” bidirectional data flow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def running_average():\n",
        "    \"\"\"Coroutine: send numbers in, get running average back.\"\"\"\n",
        "    total = 0.0\n",
        "    count = 0\n",
        "    value = None\n",
        "    while True:\n",
        "        value = yield (total / count if count else 0)   # yield avg, receive next\n",
        "        total += value\n",
        "        count += 1\n",
        "\n",
        "\n",
        "gen = running_average()\n",
        "next(gen)   # prime the coroutine (advance to first yield)\n",
        "\n",
        "print(\"=== Running average coroutine ===\")\n",
        "for n in [10, 20, 30, 40, 50]:\n",
        "    avg = gen.send(n)\n",
        "    print(f'  After sending {n:>3}: running average = {avg:.1f}')\n",
        "\n",
        "gen.close()\n"
      ],
      "id": "pm0XFwzDGV9w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XStNQ6KWGV9w"
      },
      "source": [
        "---\n",
        "## âš¡ Topic 6: Asyncio (async / await)\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "XStNQ6KWGV9w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju9g_g2kGV9w"
      },
      "source": [
        "### What is it?\n",
        "**Asyncio** provides single-threaded concurrency via cooperative multitasking.\n",
        "Coroutines voluntarily yield control at `await` points, letting the event loop run\n",
        "other coroutines while waiting for I/O.\n",
        "\n",
        "### The mental model\n",
        "```\n",
        "Thread-based:   Thread1 [=====WAIT=====][===RUN===]\n",
        "                Thread2        [===RUN===][=====WAIT=====]\n",
        "\n",
        "Asyncio:        Loop    [==RUN==][await][==RUN==][await][==RUN==]\n",
        "                         task A          task B          task A\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> FastAPI / aiohttp servers Â· Web scrapers Â· Real-time chat Â· IoT data ingestion\n",
        "> Â· Concurrent DB queries with asyncpg\n"
      ],
      "id": "ju9g_g2kGV9w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Pwu5pZk2GV9x"
      },
      "outputs": [],
      "source": [
        "import asyncio, time, random\n",
        "\n",
        "# â”€â”€ Simulated async I/O operations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "async def fetch_user(user_id: int) -> dict:\n",
        "    \"\"\"Simulate a database or HTTP call with variable latency.\"\"\"\n",
        "    delay = random.uniform(0.05, 0.2)\n",
        "    await asyncio.sleep(delay)        # yield control while 'waiting for I/O'\n",
        "    return {'id': user_id, 'name': f'User_{user_id}', 'latency_ms': round(delay*1000)}\n",
        "\n",
        "\n",
        "async def fetch_orders(user_id: int) -> list:\n",
        "    delay = random.uniform(0.05, 0.15)\n",
        "    await asyncio.sleep(delay)\n",
        "    return [{'order_id': user_id * 10 + i} for i in range(3)]\n",
        "\n",
        "\n",
        "# â”€â”€ Sequential vs Concurrent comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "async def load_dashboard_sequential(user_ids):\n",
        "    \"\"\"Awaits each call one-by-one.\"\"\"\n",
        "    results = []\n",
        "    for uid in user_ids:\n",
        "        user   = await fetch_user(uid)\n",
        "        orders = await fetch_orders(uid)\n",
        "        results.append({'user': user, 'orders': orders})\n",
        "    return results\n",
        "\n",
        "\n",
        "async def load_dashboard_concurrent(user_ids):\n",
        "    \"\"\"Fires all coroutines at once with gather().\"\"\"\n",
        "    tasks = [\n",
        "        asyncio.gather(fetch_user(uid), fetch_orders(uid))\n",
        "        for uid in user_ids\n",
        "    ]\n",
        "    pairs = await asyncio.gather(*tasks)\n",
        "    return [{'user': u, 'orders': o} for u, o in pairs]\n",
        "\n",
        "\n",
        "# â”€â”€ Semaphore: limit concurrency â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "async def controlled_fetch(sem: asyncio.Semaphore, uid: int) -> dict:\n",
        "    async with sem:          # blocks when 3 coroutines are already active\n",
        "        return await fetch_user(uid)\n",
        "\n",
        "\n",
        "async def main():\n",
        "    user_ids = list(range(1, 11))   # 10 users\n",
        "\n",
        "    # Sequential\n",
        "    t0 = time.monotonic()\n",
        "    await load_dashboard_sequential(user_ids)\n",
        "    seq_time = time.monotonic() - t0\n",
        "\n",
        "    # Concurrent\n",
        "    t0 = time.monotonic()\n",
        "    results = await load_dashboard_concurrent(user_ids)\n",
        "    con_time = time.monotonic() - t0\n",
        "\n",
        "    print(f\"Sequential:  {seq_time:.2f}s\")\n",
        "    print(f\"Concurrent:  {con_time:.2f}s  ({seq_time/con_time:.1f}x faster)\")\n",
        "    print(f\"\\nSample result: {results[0]['user']}\")\n",
        "\n",
        "    # Semaphore demo (max 3 concurrent)\n",
        "    sem = asyncio.Semaphore(3)\n",
        "    t0  = time.monotonic()\n",
        "    sem_results = await asyncio.gather(*[controlled_fetch(sem, uid) for uid in user_ids])\n",
        "    sem_time = time.monotonic() - t0\n",
        "    print(f\"\\nWith Semaphore(3): {sem_time:.2f}s\")\n",
        "    print(f\"Fetched {len(sem_results)} users\")\n",
        "\n",
        "\n",
        "asyncio.run(main())\n"
      ],
      "id": "Pwu5pZk2GV9x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rutU5mWRGV9x"
      },
      "source": [
        "---\n",
        "## ğŸ§µ Topic 7: Multithreading\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "rutU5mWRGV9x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUMRZAmOGV9x"
      },
      "source": [
        "### What is it?\n",
        "Python's `threading` module runs multiple threads in the **same process and memory space**.\n",
        "Due to the GIL, only one thread executes Python bytecode at a time â€” but threads overlap\n",
        "on I/O waits, making them useful for **I/O-bound parallelism**.\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Background workers in web apps Â· Parallel file downloads Â· GUI responsiveness\n",
        "> Â· Database connection pools Â· Concurrent API polling\n",
        "\n",
        "### Thread safety tools\n",
        "| Tool | Purpose |\n",
        "|------|---------|\n",
        "| `threading.Lock` | Mutual exclusion |\n",
        "| `threading.Event` | Signal between threads |\n",
        "| `queue.Queue` | Thread-safe data sharing |\n",
        "| `concurrent.futures.ThreadPoolExecutor` | High-level pool |\n"
      ],
      "id": "JUMRZAmOGV9x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "_iDsIG6dGV9x"
      },
      "outputs": [],
      "source": [
        "import threading, queue, time, random\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# â”€â”€ Thread-safe counter with Lock â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class SafeCounter:\n",
        "    def __init__(self):\n",
        "        self.value = 0\n",
        "        self._lock = threading.Lock()\n",
        "\n",
        "    def increment(self, n=1):\n",
        "        with self._lock:            # only one thread at a time\n",
        "            self.value += n\n",
        "\n",
        "\n",
        "counter = SafeCounter()\n",
        "threads = [threading.Thread(target=counter.increment, args=(1,)) for _ in range(1000)]\n",
        "for t in threads: t.start()\n",
        "for t in threads: t.join()\n",
        "print(f\"Counter (should be 1000): {counter.value}\")\n",
        "\n",
        "\n",
        "# â”€â”€ Producer / Consumer with Queue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def producer(q: queue.Queue, items: list):\n",
        "    for item in items:\n",
        "        time.sleep(random.uniform(0.01, 0.05))   # simulate data arrival\n",
        "        q.put(item)\n",
        "        print(f'  ğŸ“¥ Produced: {item}')\n",
        "    q.put(None)   # sentinel\n",
        "\n",
        "\n",
        "def consumer(q: queue.Queue, results: list):\n",
        "    while True:\n",
        "        item = q.get()\n",
        "        if item is None:\n",
        "            break\n",
        "        time.sleep(random.uniform(0.01, 0.03))   # simulate processing\n",
        "        results.append(item * 2)\n",
        "        print(f'  ğŸ“¤ Consumed: {item} â†’ {item*2}')\n",
        "        q.task_done()\n",
        "\n",
        "\n",
        "data    = [10, 20, 30, 40, 50]\n",
        "q       = queue.Queue(maxsize=3)   # buffer of 3\n",
        "results = []\n",
        "\n",
        "print(\"\\n=== Producer/Consumer demo ===\")\n",
        "p = threading.Thread(target=producer, args=(q, data))\n",
        "c = threading.Thread(target=consumer, args=(q, results))\n",
        "p.start(); c.start()\n",
        "p.join();  c.join()\n",
        "print(f\"Results: {sorted(results)}\")\n",
        "\n",
        "\n",
        "# â”€â”€ ThreadPoolExecutor for parallel I/O tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def simulate_api_call(endpoint: str) -> dict:\n",
        "    time.sleep(random.uniform(0.05, 0.2))\n",
        "    return {'endpoint': endpoint, 'status': 200, 'data': f'response_from_{endpoint}'}\n",
        "\n",
        "\n",
        "endpoints = ['/users', '/products', '/orders', '/analytics', '/health']\n",
        "\n",
        "print(\"\\n=== ThreadPoolExecutor (parallel API calls) ===\")\n",
        "t0 = time.monotonic()\n",
        "with ThreadPoolExecutor(max_workers=5) as pool:\n",
        "    futures = {pool.submit(simulate_api_call, ep): ep for ep in endpoints}\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        print(f'  âœ“ {result[\"endpoint\"]} â†’ {result[\"data\"]}')\n",
        "print(f\"All calls completed in {time.monotonic()-t0:.2f}s (would be ~0.75s sequentially)\")\n"
      ],
      "id": "_iDsIG6dGV9x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j34iQTWGV9y"
      },
      "source": [
        "---\n",
        "## ğŸ–¥ï¸ Topic 8: Multiprocessing\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "4j34iQTWGV9y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up9IViw4GV9y"
      },
      "source": [
        "### What is it?\n",
        "`multiprocessing` spawns separate OS processes, each with its **own Python interpreter\n",
        "and GIL**. True CPU parallelism is achieved because multiple cores run simultaneously.\n",
        "\n",
        "### GIL-free parallelism\n",
        "```\n",
        "Threading (GIL):          Process 1: [run][WAIT][run][WAIT]\n",
        "                          Process 2:         [WAIT][run][WAIT]  â† blocked by GIL\n",
        "\n",
        "Multiprocessing (no GIL): Process 1: [run][run][run][run]  â† full core\n",
        "                           Process 2: [run][run][run][run]  â† full core\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> ML training data preprocessing Â· Image/video batch processing\n",
        "> Â· Scientific computation Â· Parallel test suites Â· CPU-intensive APIs\n"
      ],
      "id": "up9IViw4GV9y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "ws-e5GUOGV9y"
      },
      "outputs": [],
      "source": [
        "import multiprocessing, time, math\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# â”€â”€ CPU-intensive task â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def is_prime(n: int) -> bool:\n",
        "    \"\"\"CPU-bound: check if n is prime.\"\"\"\n",
        "    if n < 2: return False\n",
        "    if n < 4: return True\n",
        "    if n % 2 == 0 or n % 3 == 0: return False\n",
        "    i = 5\n",
        "    while i * i <= n:\n",
        "        if n % i == 0 or n % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "\n",
        "\n",
        "def count_primes_in_range(args):\n",
        "    \"\"\"Count primes between start and end â€” runs in a worker process.\"\"\"\n",
        "    start, end = args\n",
        "    return sum(1 for n in range(start, end) if is_prime(n))\n",
        "\n",
        "\n",
        "# â”€â”€ Sequential baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "N = 500_000\n",
        "print(f\"Counting primes up to {N:,} ...\")\n",
        "\n",
        "t0 = time.monotonic()\n",
        "seq_count = count_primes_in_range((2, N))\n",
        "seq_time  = time.monotonic() - t0\n",
        "print(f\"  Sequential: {seq_count:,} primes in {seq_time:.2f}s\")\n",
        "\n",
        "\n",
        "# â”€â”€ Parallel with ProcessPoolExecutor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "cpu_count = multiprocessing.cpu_count()\n",
        "chunk     = N // cpu_count\n",
        "ranges    = [(i * chunk, (i + 1) * chunk) for i in range(cpu_count)]\n",
        "# make sure we cover the full range\n",
        "ranges[-1] = (ranges[-1][0], N)\n",
        "\n",
        "t0 = time.monotonic()\n",
        "with ProcessPoolExecutor(max_workers=cpu_count) as pool:\n",
        "    counts   = list(pool.map(count_primes_in_range, ranges))\n",
        "par_count = sum(counts)\n",
        "par_time  = time.monotonic() - t0\n",
        "\n",
        "print(f\"  Parallel ({cpu_count} cores): {par_count:,} primes in {par_time:.2f}s\")\n",
        "print(f\"  Speedup: {seq_time/par_time:.1f}x\")\n",
        "assert seq_count == par_count, \"Results must match!\"\n",
        "print(\"  âœ“ Results match\")\n"
      ],
      "id": "ws-e5GUOGV9y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "YCcDSt6aGV9y"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Shared memory between processes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "from multiprocessing import Value, Array, Process\n",
        "\n",
        "def worker_shared(counter, lock):\n",
        "    for _ in range(100):\n",
        "        with lock:\n",
        "            counter.value += 1\n",
        "\n",
        "\n",
        "shared_counter = Value('i', 0)   # shared integer\n",
        "lock           = multiprocessing.Lock()\n",
        "\n",
        "procs = [Process(target=worker_shared, args=(shared_counter, lock)) for _ in range(5)]\n",
        "for p in procs: p.start()\n",
        "for p in procs: p.join()\n",
        "print(f\"Shared counter (should be 500): {shared_counter.value}\")\n"
      ],
      "id": "YCcDSt6aGV9y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6I0BhkGV9y"
      },
      "source": [
        "---\n",
        "## ğŸ” Topic 9: Global Interpreter Lock (GIL)\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "gc6I0BhkGV9y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Ccv5zMGV9y"
      },
      "source": [
        "### What is it?\n",
        "The **GIL** is a mutex in CPython that allows only **one thread to execute Python\n",
        "bytecode at a time**. It protects Python's internal reference-counting from race\n",
        "conditions â€” but prevents true multi-threaded CPU parallelism.\n",
        "\n",
        "### Key facts\n",
        "- **Released** during C-level I/O (socket, file reads) â†’ threads overlap on I/O âœ…\n",
        "- **Released** by NumPy/SciPy during C loops â†’ threads can parallelize âœ…\n",
        "- **Held** during pure Python bytecode execution â†’ threads queue up âŒ\n",
        "- **Python 3.13+** introduces a free-threaded (no-GIL) build option ğŸ”œ\n",
        "\n",
        "### Impact on your code\n",
        "| Workload | Threading | Multiprocessing |\n",
        "|----------|-----------|-----------------|\n",
        "| I/O-bound (network, disk) | âœ… Works great | Overkill |\n",
        "| CPU-bound (pure Python) | âŒ No speedup | âœ… Use this |\n",
        "| CPU-bound (NumPy/C ext.) | âœ… Works | âœ… Also works |\n"
      ],
      "id": "F4Ccv5zMGV9y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "fGO4CfSdGV9z"
      },
      "outputs": [],
      "source": [
        "import threading, multiprocessing, time\n",
        "\n",
        "def cpu_burn(n: int):\n",
        "    \"\"\"Pure CPU work â€” counts down. GIL is held throughout.\"\"\"\n",
        "    while n > 0:\n",
        "        n -= 1\n",
        "\n",
        "N = 10_000_000   # reduced for notebook speed\n",
        "\n",
        "# â”€â”€ 1. Single thread (baseline) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "t0 = time.monotonic()\n",
        "cpu_burn(N)\n",
        "single_time = time.monotonic() - t0\n",
        "print(f\"Single thread:   {single_time:.3f}s\")\n",
        "\n",
        "# â”€â”€ 2. Two threads â€” GIL prevents true parallelism â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "t0 = time.monotonic()\n",
        "t1 = threading.Thread(target=cpu_burn, args=(N // 2,))\n",
        "t2 = threading.Thread(target=cpu_burn, args=(N // 2,))\n",
        "t1.start(); t2.start()\n",
        "t1.join();  t2.join()\n",
        "thread_time = time.monotonic() - t0\n",
        "print(f\"Two threads:     {thread_time:.3f}s  â† ~same or SLOWER (GIL overhead)\")\n",
        "\n",
        "# â”€â”€ 3. Two processes â€” real parallelism â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "t0 = time.monotonic()\n",
        "p1 = multiprocessing.Process(target=cpu_burn, args=(N // 2,))\n",
        "p2 = multiprocessing.Process(target=cpu_burn, args=(N // 2,))\n",
        "p1.start(); p2.start()\n",
        "p1.join();  p2.join()\n",
        "proc_time = time.monotonic() - t0\n",
        "print(f\"Two processes:   {proc_time:.3f}s  â† ~2x speedup on 2 cores\")\n",
        "\n",
        "ratio = single_time / proc_time\n",
        "print(f\"\\nConclusion: Processes gave {ratio:.1f}x speedup; threads gave\"\n",
        "      f\" {single_time/thread_time:.1f}x (GIL is real!)\")\n"
      ],
      "id": "fGO4CfSdGV9z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsoNOEeIGV9z"
      },
      "source": [
        "---\n",
        "## â™»ï¸ Topic 10: Memory Management & Garbage Collection\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "HsoNOEeIGV9z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1372DvKeGV9z"
      },
      "source": [
        "### What is it?\n",
        "CPython uses **reference counting** as its primary strategy â€” every object tracks\n",
        "how many references point to it and is freed *immediately* when the count reaches zero.\n",
        "\n",
        "A **cyclic garbage collector** (in the `gc` module) handles reference cycles that\n",
        "reference counting alone cannot break.\n",
        "\n",
        "### Three generations\n",
        "Objects are promoted through 3 generations; long-lived objects are collected less often:\n",
        "```\n",
        "Gen 0 (new)     threshold=700  â† collected most frequently\n",
        "Gen 1 (survived 1 collection)  threshold=10\n",
        "Gen 2 (long-lived)             threshold=10  â† collected rarely\n",
        "```\n"
      ],
      "id": "1372DvKeGV9z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "NLttYxf3GV9z"
      },
      "outputs": [],
      "source": [
        "import gc, sys, tracemalloc\n",
        "\n",
        "# â”€â”€ Reference counting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "x = []\n",
        "print(f\"Refs to x after creation:      {sys.getrefcount(x)}\")  # 2: x + getrefcount arg\n",
        "\n",
        "y = x\n",
        "print(f\"Refs to x after y=x:           {sys.getrefcount(x)}\")  # 3\n",
        "\n",
        "del y\n",
        "print(f\"Refs to x after del y:         {sys.getrefcount(x)}\")  # 2\n",
        "\n",
        "# â”€â”€ Reference cycle â€” memory leak without cyclic GC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class Node:\n",
        "    def __init__(self, name):\n",
        "        self.name  = name\n",
        "        self.child = None\n",
        "    def __del__(self):\n",
        "        pass  # called when freed\n",
        "\n",
        "gc.disable()   # pause cyclic collector so we can observe the leak\n",
        "gc.collect()\n",
        "\n",
        "before = len(gc.get_objects())\n",
        "\n",
        "a = Node('A')\n",
        "b = Node('B')\n",
        "a.child = b    # A â†’ B\n",
        "b.child = a    # B â†’ A  â† cycle!\n",
        "\n",
        "del a, b       # refcount never hits 0 â€” MEMORY LEAK without cyclic GC\n",
        "\n",
        "leaked = len(gc.get_objects()) - before\n",
        "print(f\"\\nObjects leaked (cycle, GC disabled): {leaked}\")\n",
        "\n",
        "gc.enable()\n",
        "collected = gc.collect()   # cyclic GC finds and frees the cycle\n",
        "print(f\"gc.collect() freed: {collected} objects\")\n",
        "\n",
        "# â”€â”€ tracemalloc â€” find what's using memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tracemalloc.start()\n",
        "\n",
        "big_list = [bytearray(1024) for _ in range(1000)]   # 1 MB\n",
        "\n",
        "snapshot = tracemalloc.take_snapshot()\n",
        "top = snapshot.statistics('lineno')\n",
        "print(\"\\nTop memory consumers:\")\n",
        "for stat in top[:3]:\n",
        "    print(f\"  {stat}\")\n",
        "\n",
        "del big_list\n",
        "tracemalloc.stop()\n",
        "\n",
        "# â”€â”€ Tuning GC thresholds for high-throughput servers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"\\nDefault thresholds: {gc.get_threshold()}\")\n",
        "gc.set_threshold(1000, 20, 20)   # fewer collections = lower pause frequency\n",
        "print(f\"Tuned thresholds:   {gc.get_threshold()}\")\n"
      ],
      "id": "NLttYxf3GV9z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Bh_Q1hGV90"
      },
      "source": [
        "---\n",
        "## ğŸ”— Topic 11: Weak References\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "S0Bh_Q1hGV90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTdLr7-mGV90"
      },
      "source": [
        "### What is it?\n",
        "A **weak reference** lets you hold a reference to an object **without incrementing\n",
        "its reference count**. If no strong references remain, the object is garbage collected\n",
        "and the weak reference becomes `None`.\n",
        "\n",
        "### Strong vs Weak\n",
        "```python\n",
        "strong = obj   # refcount += 1  â€” obj won't be GC'd while this exists\n",
        "weak   = weakref.ref(obj)   # refcount unchanged â€” obj may disappear\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> LRU caches where entries should vanish when unused\n",
        "> Â· Observer/event systems where listeners shouldn't own the source\n",
        "> Â· Object registries in plugin architectures\n"
      ],
      "id": "cTdLr7-mGV90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "KmtiHBsjGV90"
      },
      "outputs": [],
      "source": [
        "import weakref, gc\n",
        "\n",
        "class ExpensiveResource:\n",
        "    def __init__(self, key: str):\n",
        "        self.key  = key\n",
        "        self.data = list(range(10_000))   # simulate expensive object\n",
        "        print(f'  [+] Created {key!r}')\n",
        "\n",
        "    def __del__(self):\n",
        "        print(f'  [-] Freed   {key!r}' if False else f'  [-] Freed   {self.key!r}')\n",
        "\n",
        "    def compute(self):\n",
        "        return sum(self.data)\n",
        "\n",
        "\n",
        "# â”€â”€ WeakValueDictionary: cache that releases entries automatically â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class SmartCache:\n",
        "    def __init__(self):\n",
        "        self._store = weakref.WeakValueDictionary()\n",
        "\n",
        "    def get_or_create(self, key: str) -> ExpensiveResource:\n",
        "        obj = self._store.get(key)\n",
        "        if obj is None:\n",
        "            print(f'  MISS â€” creating {key!r}')\n",
        "            obj = ExpensiveResource(key)\n",
        "            self._store[key] = obj\n",
        "        else:\n",
        "            print(f'  HIT  â€” reusing {key!r}')\n",
        "        return obj\n",
        "\n",
        "\n",
        "cache = SmartCache()\n",
        "\n",
        "print(\"=== First access â€” creates objects ===\")\n",
        "r1 = cache.get_or_create('model_weights')\n",
        "r2 = cache.get_or_create('embeddings')\n",
        "\n",
        "print(\"\\n=== Second access â€” cache hits ===\")\n",
        "r1b = cache.get_or_create('model_weights')\n",
        "print(f'Same object? {r1 is r1b}')  # True\n",
        "\n",
        "print(\"\\n=== Releasing strong references ===\")\n",
        "del r1, r1b, r2\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n=== Re-access after GC â€” cache misses again ===\")\n",
        "r3 = cache.get_or_create('model_weights')   # recreated\n",
        "del r3\n",
        "\n",
        "# â”€â”€ weakref.ref â€” low-level callback on death â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n=== weakref.ref with finalizer callback ===\")\n",
        "obj = ExpensiveResource('singleton')\n",
        "\n",
        "def on_death(ref):\n",
        "    print(f'  ğŸ’€ Weak ref notified: object is gone')\n",
        "\n",
        "weak = weakref.ref(obj, on_death)\n",
        "print(f'Alive: {weak()}')\n",
        "del obj\n",
        "gc.collect()\n",
        "print(f'Dead:  {weak()}')\n"
      ],
      "id": "KmtiHBsjGV90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtxnEvltGV91"
      },
      "source": [
        "---\n",
        "## ğŸ—‚ï¸ Topic 12: __slots__\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "PtxnEvltGV91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDZrcb7lGV91"
      },
      "source": [
        "### What is it?\n",
        "By default, Python stores instance attributes in a per-instance `__dict__` (a hash map).\n",
        "Defining `__slots__` replaces this with a compact, fixed-size array of slots â€”\n",
        "reducing per-instance memory by **40â€“60%** and speeding up attribute access.\n",
        "\n",
        "### Without vs With\n",
        "```python\n",
        "class Normal:               # each instance has a __dict__ (hash map overhead)\n",
        "    def __init__(self): self.x = 1\n",
        "\n",
        "class Slotted:              # each instance has fixed-size C-level slots\n",
        "    __slots__ = ('x',)\n",
        "    def __init__(self): self.x = 1\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Financial tick data (millions of events/second) Â· ML feature vectors\n",
        "> Â· Network packet objects Â· Any class instantiated millions of times\n"
      ],
      "id": "tDZrcb7lGV91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Q9MQ6rzoGV92"
      },
      "outputs": [],
      "source": [
        "import sys, timeit\n",
        "\n",
        "# â”€â”€ Memory comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class TradeEvent:\n",
        "    \"\"\"Without __slots__ â€” each instance carries a __dict__.\"\"\"\n",
        "    def __init__(self, symbol, price, qty, ts):\n",
        "        self.symbol = symbol\n",
        "        self.price  = price\n",
        "        self.qty    = qty\n",
        "        self.ts     = ts\n",
        "\n",
        "\n",
        "class TradeEventSlotted:\n",
        "    \"\"\"With __slots__ â€” no per-instance __dict__.\"\"\"\n",
        "    __slots__ = ('symbol', 'price', 'qty', 'ts')\n",
        "\n",
        "    def __init__(self, symbol, price, qty, ts):\n",
        "        self.symbol = symbol\n",
        "        self.price  = price\n",
        "        self.qty    = qty\n",
        "        self.ts     = ts\n",
        "\n",
        "\n",
        "t1 = TradeEvent('AAPL', 182.35, 100, 1_700_000_000)\n",
        "t2 = TradeEventSlotted('AAPL', 182.35, 100, 1_700_000_000)\n",
        "\n",
        "size_normal  = sys.getsizeof(t1) + sys.getsizeof(t1.__dict__)\n",
        "size_slotted = sys.getsizeof(t2)\n",
        "\n",
        "print(f\"Without __slots__: {size_normal} bytes\")\n",
        "print(f\"With    __slots__: {size_slotted} bytes\")\n",
        "print(f\"Reduction:         {(1 - size_slotted/size_normal)*100:.0f}%\")\n",
        "\n",
        "# â”€â”€ Speed comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "setup = \"from __main__ import TradeEvent, TradeEventSlotted; t1=TradeEvent('AAPL',1,1,1); t2=TradeEventSlotted('AAPL',1,1,1)\"\n",
        "t_normal  = timeit.timeit(\"t1.price = 183.0; _ = t1.price\", setup=setup, number=1_000_000)\n",
        "t_slotted = timeit.timeit(\"t2.price = 183.0; _ = t2.price\", setup=setup, number=1_000_000)\n",
        "print(f\"\\nAttribute access (1M iterations):\")\n",
        "print(f\"  Normal:  {t_normal:.3f}s\")\n",
        "print(f\"  Slotted: {t_slotted:.3f}s  ({t_normal/t_slotted:.2f}x faster)\")\n",
        "\n",
        "# â”€â”€ Constraint: cannot add arbitrary attributes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "try:\n",
        "    t2.volume = 5000   # not in __slots__!\n",
        "except AttributeError as e:\n",
        "    print(f\"\\nâœ— {e}\")\n",
        "\n",
        "# â”€â”€ hasattr checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"\\nhas __dict__: normal={hasattr(t1,'__dict__')}, slotted={hasattr(t2,'__dict__')}\")\n",
        "print(f\"has __slots__: normal={hasattr(t1,'__slots__')}, slotted={hasattr(t2,'__slots__')}\")\n"
      ],
      "id": "Q9MQ6rzoGV92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bkNjwi5GV92"
      },
      "source": [
        "---\n",
        "## ğŸ“‹ Topic 13: Abstract Base Classes (ABC)\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "7bkNjwi5GV92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU7dMG5uGV92"
      },
      "source": [
        "### What is it?\n",
        "ABCs define **interfaces** â€” classes with abstract methods that subclasses *must* implement.\n",
        "Python raises `TypeError` when you try to instantiate a class with unimplemented abstract methods.\n",
        "\n",
        "### Why use ABCs over duck typing?\n",
        "- Catch missing method implementations **at instantiation time**, not at call time\n",
        "- Enable meaningful `isinstance()` checks across plugin implementations\n",
        "- Serve as documentation of the required interface\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Payment gateway adapters Â· Storage backends (S3, GCS, local) Â· Notification channels\n",
        "> Â· Plugin systems Â· serialisation codecs\n"
      ],
      "id": "eU7dMG5uGV92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "RP2RBFvBGV92"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from decimal import Decimal\n",
        "\n",
        "@dataclass\n",
        "class PaymentResult:\n",
        "    success:        bool\n",
        "    transaction_id: str\n",
        "    message:        str\n",
        "\n",
        "\n",
        "class PaymentGateway(ABC):\n",
        "    \"\"\"Interface contract: all payment backends must implement these methods.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def charge(self, amount: Decimal, card_token: str) -> PaymentResult:\n",
        "        \"\"\"Charge the card.\"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def refund(self, transaction_id: str, amount: Decimal) -> PaymentResult:\n",
        "        \"\"\"Issue a refund.\"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def verify_card(self, card_token: str) -> bool:\n",
        "        \"\"\"Check if the card is valid.\"\"\"\n",
        "        ...\n",
        "\n",
        "    def charge_if_valid(self, amount: Decimal, card_token: str) -> PaymentResult:\n",
        "        \"\"\"Template method â€” calls abstract methods.\"\"\"\n",
        "        if not self.verify_card(card_token):\n",
        "            return PaymentResult(False, '', 'Card verification failed')\n",
        "        return self.charge(amount, card_token)\n",
        "\n",
        "\n",
        "# â”€â”€ Concrete implementations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class StripeGateway(PaymentGateway):\n",
        "    def charge(self, amount, card_token):\n",
        "        return PaymentResult(True, 'ch_stripe_123', f'Stripe charged ${amount}')\n",
        "    def refund(self, transaction_id, amount):\n",
        "        return PaymentResult(True, 're_stripe_456', f'Stripe refunded ${amount}')\n",
        "    def verify_card(self, card_token):\n",
        "        return card_token.startswith('tok_')\n",
        "\n",
        "\n",
        "class PayPalGateway(PaymentGateway):\n",
        "    def charge(self, amount, card_token):\n",
        "        return PaymentResult(True, 'pp_789', f'PayPal charged ${amount}')\n",
        "    def refund(self, transaction_id, amount):\n",
        "        return PaymentResult(True, 'pp_ref_012', f'PayPal refunded ${amount}')\n",
        "    def verify_card(self, card_token):\n",
        "        return True\n",
        "\n",
        "\n",
        "# â”€â”€ Cannot instantiate abstract class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "try:\n",
        "    PaymentGateway()\n",
        "except TypeError as e:\n",
        "    print(f\"âœ— {e}\")\n",
        "\n",
        "# â”€â”€ Cannot use incomplete implementation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class IncompleteGateway(PaymentGateway):\n",
        "    def charge(self, amount, card_token):\n",
        "        return PaymentResult(True, 'x', 'ok')\n",
        "    # forgot refund and verify_card!\n",
        "\n",
        "try:\n",
        "    IncompleteGateway()\n",
        "except TypeError as e:\n",
        "    print(f\"âœ— {e}\")\n",
        "\n",
        "# â”€â”€ Correct usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def process_order(gateway: PaymentGateway, amount, token):\n",
        "    result = gateway.charge_if_valid(amount, token)\n",
        "    print(f\"  {'âœ“' if result.success else 'âœ—'} {result.message}\")\n",
        "    return result\n",
        "\n",
        "print(\"\\n=== Processing orders ===\")\n",
        "process_order(StripeGateway(),  Decimal('49.99'), 'tok_visa_xxxx')\n",
        "process_order(PayPalGateway(),  Decimal('29.99'), 'pp_email_abc')\n",
        "process_order(StripeGateway(),  Decimal('19.99'), 'invalid_token')\n"
      ],
      "id": "RP2RBFvBGV92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfr6mCfDGV93"
      },
      "source": [
        "---\n",
        "## ğŸ’ Topic 14: Monkey Patching\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "Bfr6mCfDGV93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uas2vcKMGV93"
      },
      "source": [
        "### What is it?\n",
        "**Monkey patching** replaces or augments attributes of a module or class *at runtime*.\n",
        "It's widely used in testing (mocking external services), adding observability to\n",
        "third-party code, and applying emergency fixes without forking a library.\n",
        "\n",
        "### Real-World Use Cases\n",
        "> `unittest.mock.patch` in tests Â· Gevent's cooperative I/O patches\n",
        "> Â· Adding timing/logging to third-party code Â· Hot-fixing library bugs\n"
      ],
      "id": "uas2vcKMGV93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "1q6FQxD0GV93"
      },
      "outputs": [],
      "source": [
        "import time, functools\n",
        "from unittest.mock import patch, MagicMock\n",
        "\n",
        "# â”€â”€ 1. Basic monkey patch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class EmailService:\n",
        "    def send(self, to: str, subject: str, body: str) -> bool:\n",
        "        # In real code this would hit an SMTP server\n",
        "        raise ConnectionError(\"No SMTP server available in notebook!\")\n",
        "\n",
        "\n",
        "email_service = EmailService()\n",
        "\n",
        "# Save original, replace with mock\n",
        "_original_send = EmailService.send\n",
        "EmailService.send = lambda self, *a, **kw: True   # always succeeds\n",
        "\n",
        "result = email_service.send('alice@example.com', 'Hello', 'Body')\n",
        "print(f\"Patched send returned: {result}\")\n",
        "\n",
        "EmailService.send = _original_send   # restore\n",
        "\n",
        "\n",
        "# â”€â”€ 2. unittest.mock.patch as context manager â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def send_welcome_email(service, user_email: str) -> bool:\n",
        "    \"\"\"Function under test â€” depends on EmailService.send.\"\"\"\n",
        "    return service.send(user_email, 'Welcome!', 'Thanks for signing up.')\n",
        "\n",
        "\n",
        "print(\"\\n=== Unit test with mock.patch ===\")\n",
        "with patch.object(EmailService, 'send', return_value=True) as mock_send:\n",
        "    result = send_welcome_email(email_service, 'bob@example.com')\n",
        "    mock_send.assert_called_once_with('bob@example.com', 'Welcome!', 'Thanks for signing up.')\n",
        "    print(f\"  âœ“ Email sent: {result}\")\n",
        "    print(f\"  âœ“ Called with: {mock_send.call_args}\")\n",
        "\n",
        "\n",
        "# â”€â”€ 3. Runtime instrumentation â€” add timing to any function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def instrument(module, func_name: str):\n",
        "    \"\"\"Wraps module.func_name with a timing layer without touching source code.\"\"\"\n",
        "    original = getattr(module, func_name)\n",
        "\n",
        "    @functools.wraps(original)\n",
        "    def timed(*args, **kwargs):\n",
        "        t0  = time.perf_counter()\n",
        "        res = original(*args, **kwargs)\n",
        "        ms  = (time.perf_counter() - t0) * 1000\n",
        "        print(f'  [TIMING] {module.__name__}.{func_name}() â†’ {ms:.3f}ms')\n",
        "        return res\n",
        "\n",
        "    setattr(module, func_name, timed)\n",
        "    return original   # return original so we can restore later\n",
        "\n",
        "\n",
        "import json\n",
        "original_dumps = instrument(json, 'dumps')\n",
        "\n",
        "json.dumps({'hello': 'world', 'numbers': list(range(100))})\n",
        "json.dumps([1, 2, 3])\n",
        "\n",
        "json.dumps = original_dumps   # restore\n",
        "print(\"  Restored json.dumps\")\n"
      ],
      "id": "1q6FQxD0GV93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feNZA0P5GV93"
      },
      "source": [
        "---\n",
        "## ğŸ“¦ Topic 15: Function Closures\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "feNZA0P5GV93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxNdvJ5xGV93"
      },
      "source": [
        "### What is it?\n",
        "A **closure** is a function that *captures variables from its enclosing scope*\n",
        "even after that scope has exited. Closures are the mechanism behind decorators,\n",
        "factory functions, and stateful callbacks.\n",
        "\n",
        "```python\n",
        "def outer():\n",
        "    x = 10              # â† captured by inner\n",
        "    def inner():\n",
        "        return x        # â† accesses x from enclosing scope\n",
        "    return inner        # outer() has exited, but x lives on in inner's closure\n",
        "\n",
        "f = outer()\n",
        "f()   # â†’ 10\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Currency/unit formatters Â· Middleware pipelines Â· Event callbacks\n",
        "> Â· Partial application Â· Memoization helpers\n"
      ],
      "id": "BxNdvJ5xGV93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "ByQgBwRBGV93"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ 1. Factory functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def make_formatter(prefix: str, suffix: str, decimals: int = 2):\n",
        "    \"\"\"Returns a specialised formatting function closed over the parameters.\"\"\"\n",
        "    def formatter(value: float) -> str:\n",
        "        return f'{prefix}{value:,.{decimals}f}{suffix}'\n",
        "    return formatter\n",
        "\n",
        "\n",
        "usd  = make_formatter('$', '')\n",
        "eur  = make_formatter('', ' â‚¬')\n",
        "gbp  = make_formatter('Â£', '')\n",
        "perc = make_formatter('', '%', decimals=1)\n",
        "\n",
        "for fn, val in [(usd, 1_234.56), (eur, 1_234.56), (gbp, 999.0), (perc, 12.345)]:\n",
        "    print(f'  {fn(val)}')\n",
        "\n",
        "\n",
        "# â”€â”€ 2. Inspect the closure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import inspect\n",
        "\n",
        "print(f\"\\nclosure vars: {[c.cell_contents for c in usd.__code__.co_freevars and usd.__closure__]}\")\n",
        "print(f\"free vars:    {usd.__code__.co_freevars}\")\n",
        "\n",
        "\n",
        "# â”€â”€ 3. Stateful closure (accumulator) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def make_accumulator(initial=0):\n",
        "    total = [initial]   # list cell is mutable â€” avoids need for 'nonlocal' in Py2\n",
        "\n",
        "    def add(value):\n",
        "        total[0] += value\n",
        "        return total[0]\n",
        "\n",
        "    def reset():\n",
        "        total[0] = initial\n",
        "\n",
        "    add.reset = reset   # attach helper to the closure function\n",
        "    return add\n",
        "\n",
        "\n",
        "sales = make_accumulator()\n",
        "print(f\"\\n  Sales: {sales(100)}\")\n",
        "print(f\"  Sales: {sales(250)}\")\n",
        "print(f\"  Sales: {sales(75)}\")\n",
        "sales.reset()\n",
        "print(f\"  After reset: {sales(50)}\")\n",
        "\n",
        "\n",
        "# â”€â”€ 4. Closure gotcha â€” late binding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n=== Late binding gotcha ===\")\n",
        "funcs_bad = [lambda: i for i in range(5)]      # all capture the SAME i\n",
        "funcs_ok  = [lambda i=i: i for i in range(5)]  # default arg captures current i\n",
        "\n",
        "print(f\"  Bad (late binding):  {[f() for f in funcs_bad]}\")   # [4,4,4,4,4]\n",
        "print(f\"  Fixed (default arg): {[f() for f in funcs_ok]}\")    # [0,1,2,3,4]\n"
      ],
      "id": "ByQgBwRBGV93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KIZjNeXGV94"
      },
      "source": [
        "---\n",
        "## ğŸ” Topic 16: Introspection & Reflection\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "-KIZjNeXGV94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ivCYfN5GV94"
      },
      "source": [
        "### What is it?\n",
        "**Introspection** â€” examining types, attributes, and call signatures at runtime.\n",
        "**Reflection** â€” modifying behaviour based on that introspection.\n",
        "\n",
        "Python exposes these via: `inspect`, `dir`, `type`, `vars`, `getattr`, `setattr`,\n",
        "`hasattr`, `isinstance`, `issubclass`.\n",
        "\n",
        "### Real-World Use Cases\n",
        "> Serialisation frameworks (pydantic, marshmallow) Â· Dependency injection containers\n",
        "> Â· CLI generators (Fire, Typer) Â· API documentation generators (FastAPI auto-docs)\n",
        "> Â· Test frameworks (pytest fixture discovery)\n"
      ],
      "id": "6ivCYfN5GV94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "sQ3AKRjLGV94"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "# â”€â”€ Explore a class at runtime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Processes data files with various transformation options.\"\"\"\n",
        "\n",
        "    MAX_BATCH = 1000\n",
        "\n",
        "    def load(self, filepath: str, encoding: str = 'utf-8') -> int:\n",
        "        \"\"\"Load data from a file. Returns row count.\"\"\"\n",
        "        return 42\n",
        "\n",
        "    def transform(self, operation: str, column: str, inplace: bool = False) -> bool:\n",
        "        \"\"\"Apply a named operation to a column.\"\"\"\n",
        "        return True\n",
        "\n",
        "    def export(self, output: str, fmt: str = 'csv', compress: bool = False) -> str:\n",
        "        \"\"\"Export data to a file. Returns output path.\"\"\"\n",
        "        return output\n",
        "\n",
        "    def _internal(self):\n",
        "        pass  # private\n",
        "\n",
        "\n",
        "proc = DataProcessor()\n",
        "\n",
        "# â”€â”€ What methods does this object have? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "public_methods = {\n",
        "    name: func\n",
        "    for name, func in inspect.getmembers(proc, predicate=inspect.ismethod)\n",
        "    if not name.startswith('_')\n",
        "}\n",
        "print(\"Public methods:\", list(public_methods))\n",
        "\n",
        "# â”€â”€ Inspect method signatures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for name, method in public_methods.items():\n",
        "    sig = inspect.signature(method)\n",
        "    print(f\"\\n  {name}{sig}\")\n",
        "    for pname, param in sig.parameters.items():\n",
        "        ann     = param.annotation if param.annotation != inspect.Parameter.empty else 'any'\n",
        "        default = f' = {param.default!r}' if param.default != inspect.Parameter.empty else ''\n",
        "        print(f'    â”œ {pname}: {ann}{default}')\n",
        "\n",
        "# â”€â”€ Auto-generate CLI dispatcher â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def auto_dispatch(obj, command: str, *cli_args):\n",
        "    methods = {n: m for n, m in inspect.getmembers(obj, inspect.ismethod)\n",
        "               if not n.startswith('_')}\n",
        "    if command not in methods:\n",
        "        print(f\"  Unknown: {command}. Available: {list(methods)}\")\n",
        "        return\n",
        "    method = methods[command]\n",
        "    sig    = inspect.signature(method)\n",
        "    params = list(sig.parameters.values())\n",
        "    coerced = []\n",
        "    for i, param in enumerate(params):\n",
        "        if i >= len(cli_args):\n",
        "            coerced.append(param.default)\n",
        "        else:\n",
        "            ann = param.annotation\n",
        "            coerced.append(ann(cli_args[i]) if ann != inspect.Parameter.empty else cli_args[i])\n",
        "    result = method(*coerced)\n",
        "    print(f\"  [{command}] â†’ {result!r}\")\n",
        "\n",
        "print(\"\\n=== Auto CLI dispatcher ===\")\n",
        "auto_dispatch(proc, 'load',      'sales.csv', 'latin-1')\n",
        "auto_dispatch(proc, 'transform', 'uppercase', 'name', 'True')\n",
        "auto_dispatch(proc, 'export',    'out.csv')\n",
        "auto_dispatch(proc, 'missing_command')\n"
      ],
      "id": "sQ3AKRjLGV94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eaCMqLSGV94"
      },
      "source": [
        "---\n",
        "## ğŸ›ï¸ Topic 17: Dynamic Attribute Access (__getattr__, __getattribute__)\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "0eaCMqLSGV94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyPY42bPGV94"
      },
      "source": [
        "### What is it?\n",
        "| Method | When called | Risk |\n",
        "|--------|-------------|------|\n",
        "| `__getattr__` | Only when *normal lookup fails* | Low â€” safe default |\n",
        "| `__getattribute__` | On *every* attribute access | High â€” infinite recursion if careless |\n",
        "\n",
        "### Real-World Use Cases\n",
        "> ORM lazy-loading (accessing `row.author` triggers a DB query)\n",
        "> Â· Remote object proxies Â· Config objects that read env vars on demand\n",
        "> Â· Attribute-driven query builders (SQLAlchemy, Django ORM `filter()`)\n"
      ],
      "id": "OyPY42bPGV94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "s4j5FGarGV95"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Lazy database row proxy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class FakeDB:\n",
        "    \"\"\"Simulates a database with a find(table, pk) method.\"\"\"\n",
        "    _tables = {\n",
        "        'users':      {1: {'id': 1, 'name': 'Alice', 'role': 'admin'},\n",
        "                       2: {'id': 2, 'name': 'Bob',   'role': 'user'}},\n",
        "        'categories': {5: {'id': 5, 'name': 'Python'},\n",
        "                       6: {'id': 6, 'name': 'Django'}},\n",
        "    }\n",
        "    _query_count = 0\n",
        "\n",
        "    def find(self, table: str, pk: int) -> dict:\n",
        "        self._query_count += 1\n",
        "        print(f'  [DB query #{self._query_count}] SELECT * FROM {table} WHERE id={pk}')\n",
        "        return self._tables.get(table, {}).get(pk)\n",
        "\n",
        "\n",
        "class LazyRow:\n",
        "    \"\"\"\n",
        "    Wraps a DB row dict and lazily fetches related rows on first access.\n",
        "    Caches results to avoid redundant queries.\n",
        "    \"\"\"\n",
        "    _RELATIONS = {'author': 'users', 'category': 'categories'}\n",
        "\n",
        "    def __init__(self, data: dict, db: FakeDB):\n",
        "        object.__setattr__(self, '_data',  data)\n",
        "        object.__setattr__(self, '_db',    db)\n",
        "        object.__setattr__(self, '_cache', {})\n",
        "\n",
        "    def __getattr__(self, name: str):\n",
        "        # Only called when normal lookup fails\n",
        "        data  = object.__getattribute__(self, '_data')\n",
        "        cache = object.__getattribute__(self, '_cache')\n",
        "        db    = object.__getattribute__(self, '_db')\n",
        "\n",
        "        if name in data:                        # direct column\n",
        "            return data[name]\n",
        "\n",
        "        rel_table = self._RELATIONS.get(name)   # try relation\n",
        "        if rel_table:\n",
        "            fk = data.get(name + '_id')\n",
        "            if fk is not None:\n",
        "                if name not in cache:\n",
        "                    cache[name] = db.find(rel_table, fk)\n",
        "                return cache[name]\n",
        "\n",
        "        raise AttributeError(f'No attribute {name!r}')\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"LazyRow({object.__getattribute__(self, '_data')})\"\n",
        "\n",
        "\n",
        "db  = FakeDB()\n",
        "row = LazyRow({\n",
        "    'id': 10, 'title': 'Getting Started', 'views': 1337,\n",
        "    'author_id': 1, 'category_id': 5\n",
        "}, db)\n",
        "\n",
        "print(\"=== Accessing plain columns (no DB query) ===\")\n",
        "print(f\"  id:    {row.id}\")\n",
        "print(f\"  title: {row.title}\")\n",
        "print(f\"  views: {row.views}\")\n",
        "print(f\"  DB queries so far: {db._query_count}\")\n",
        "\n",
        "print(\"\\n=== First access to relation â€” triggers DB query ===\")\n",
        "print(f\"  author:   {row.author}\")\n",
        "print(f\"  category: {row.category}\")\n",
        "\n",
        "print(\"\\n=== Second access â€” served from cache ===\")\n",
        "print(f\"  author:   {row.author}\")\n",
        "print(f\"  category: {row.category}\")\n",
        "print(f\"  Total DB queries: {db._query_count}  (only 2, not 4!)\")\n"
      ],
      "id": "s4j5FGarGV95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqAbrIE1GV95"
      },
      "source": [
        "---\n",
        "## âš™ï¸ Topic 18: Data Model & Dunder Methods\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "LqAbrIE1GV95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVqiPsDGV95"
      },
      "source": [
        "### What is it?\n",
        "Python's **data model** is the set of special (dunder) methods that make user-defined\n",
        "objects participate in language syntax â€” arithmetic operators, comparisons, iteration,\n",
        "hashing, string representation, and more.\n",
        "\n",
        "### Common dunder methods\n",
        "| Category | Methods |\n",
        "|----------|---------|\n",
        "| Representation | `__repr__`, `__str__`, `__format__` |\n",
        "| Arithmetic | `__add__`, `__sub__`, `__mul__`, `__truediv__`, `__neg__` |\n",
        "| Comparison | `__eq__`, `__lt__`, `__le__`, `__gt__`, `__ge__` |\n",
        "| Container | `__len__`, `__getitem__`, `__setitem__`, `__iter__`, `__contains__` |\n",
        "| Context | `__enter__`, `__exit__` |\n",
        "| Lifecycle | `__init__`, `__new__`, `__del__` |\n",
        "| Hashing | `__hash__`, `__bool__` |\n"
      ],
      "id": "csVqiPsDGV95"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "GjxywDN_GV95"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from decimal import Decimal\n",
        "from functools import total_ordering\n",
        "\n",
        "@total_ordering   # auto-generates <=, >, >= from __eq__ + __lt__\n",
        "class Money:\n",
        "    \"\"\"Immutable monetary value with currency safety.\"\"\"\n",
        "\n",
        "    def __init__(self, amount, currency: str = 'USD'):\n",
        "        self.amount   = Decimal(str(amount))\n",
        "        self.currency = currency.upper()\n",
        "\n",
        "    # â”€â”€ Representation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def __repr__(self)  -> str: return f\"Money({self.amount!r}, {self.currency!r})\"\n",
        "    def __str__(self)   -> str: return f\"{self.currency} {self.amount:,.2f}\"\n",
        "    def __format__(self, spec):return format(str(self), spec)\n",
        "\n",
        "    # â”€â”€ Equality & Comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def _assert_same_currency(self, other):\n",
        "        if not isinstance(other, Money) or other.currency != self.currency:\n",
        "            raise TypeError(f'Cannot mix {self.currency} and {getattr(other,\"currency\",\"??\")}')\n",
        "\n",
        "    def __eq__(self, other) -> bool:\n",
        "        if not isinstance(other, Money): return NotImplemented\n",
        "        self._assert_same_currency(other)\n",
        "        return self.amount == other.amount\n",
        "\n",
        "    def __lt__(self, other) -> bool:\n",
        "        self._assert_same_currency(other)\n",
        "        return self.amount < other.amount\n",
        "\n",
        "    # â”€â”€ Arithmetic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def __add__(self, other: Money) -> Money:\n",
        "        self._assert_same_currency(other)\n",
        "        return Money(self.amount + other.amount, self.currency)\n",
        "\n",
        "    def __sub__(self, other: Money) -> Money:\n",
        "        self._assert_same_currency(other)\n",
        "        return Money(self.amount - other.amount, self.currency)\n",
        "\n",
        "    def __mul__(self, factor) -> Money:\n",
        "        return Money(self.amount * Decimal(str(factor)), self.currency)\n",
        "\n",
        "    def __rmul__(self, factor) -> Money: return self.__mul__(factor)\n",
        "    def __neg__(self)          -> Money: return Money(-self.amount, self.currency)\n",
        "    def __abs__(self)          -> Money: return Money(abs(self.amount), self.currency)\n",
        "\n",
        "    # â”€â”€ Container / truth â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    def __bool__(self) -> bool: return self.amount != 0\n",
        "    def __hash__(self):         return hash((self.amount, self.currency))\n",
        "\n",
        "\n",
        "# â”€â”€ Usage demo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "price    = Money('19.99')\n",
        "tax      = Money('1.60')\n",
        "shipping = Money('4.99')\n",
        "\n",
        "print(f\"price:    {price}\")\n",
        "print(f\"tax:      {tax}\")\n",
        "print(f\"total:    {price + tax + shipping}\")\n",
        "print(f\"x3:       {(price + tax + shipping) * 3}\")\n",
        "print(f\"discount: {price - Money('5.00')}\")\n",
        "\n",
        "prices = [Money('25'), Money('10'), Money('50'), Money('5'), Money('30')]\n",
        "print(f\"\\nsorted:   {sorted(prices)}\")\n",
        "print(f\"min:      {min(prices)}\")\n",
        "print(f\"max:      {max(prices)}\")\n",
        "print(f\"sum:      {sum(prices, Money('0'))}\")\n",
        "\n",
        "print(f\"\\nbool(Money('0')): {bool(Money('0'))}\")\n",
        "print(f\"bool(Money('1')): {bool(Money('1'))}\")\n",
        "\n",
        "try:\n",
        "    Money('10', 'USD') + Money('10', 'EUR')\n",
        "except TypeError as e:\n",
        "    print(f\"\\nâœ— {e}\")\n"
      ],
      "id": "GjxywDN_GV95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqX0OvQDGV96"
      },
      "source": [
        "---\n",
        "## âš¡ Topic 19: C Extensions / CPython API\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "PqX0OvQDGV96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwJ5OzepGV96"
      },
      "source": [
        "### What is it?\n",
        "C extensions are compiled shared libraries (`.so`/`.pyd`) that CPython loads directly.\n",
        "They can bypass the GIL for pure C computation and run **10â€“100Ã— faster** than Python.\n",
        "\n",
        "### Authoring approaches\n",
        "| Tool | Best for | Difficulty |\n",
        "|------|----------|------------|\n",
        "| **Cython** | Typed Python-like syntax â†’ C | â˜…â˜…â˜† |\n",
        "| **pybind11** | C++ integration | â˜…â˜…â˜… |\n",
        "| **CFFI** | Calling existing C libraries | â˜…â˜…â˜† |\n",
        "| **ctypes** | Calling C libs (stdlib) | â˜…â˜†â˜† |\n",
        "| **CPython C API** | Full control | â˜…â˜…â˜… |\n",
        "\n",
        "### Real-World Use Cases\n",
        "> NumPy Â· Pandas Â· SciPy Â· OpenCV Â· PyTorch Â· Cryptography Â· lxml\n"
      ],
      "id": "iwJ5OzepGV96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "4fMC_AIUGV96"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ctypes â€” calling C stdlib functions (no compilation needed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import ctypes, ctypes.util, timeit, math\n",
        "\n",
        "# Load the C math library\n",
        "libm_path = ctypes.util.find_library('m')\n",
        "if libm_path:\n",
        "    libm = ctypes.CDLL(libm_path)\n",
        "    libm.sqrt.restype  = ctypes.c_double\n",
        "    libm.sqrt.argtypes = [ctypes.c_double]\n",
        "\n",
        "    # Compare Python math.sqrt vs C sqrt via ctypes\n",
        "    N = 500_000\n",
        "    t_py = timeit.timeit(lambda: math.sqrt(12345.6789), number=N)\n",
        "    t_c  = timeit.timeit(lambda: libm.sqrt(12345.6789), number=N)\n",
        "    print(f\"math.sqrt (Python): {t_py*1000:.1f}ms for {N} calls\")\n",
        "    print(f\"libm.sqrt (C):      {t_c*1000:.1f}ms  for {N} calls\")\n",
        "    print(f\"Note: ctypes overhead can make C calls slower for trivial ops!\")\n",
        "    print(f\"Results match: {abs(math.sqrt(12345.6789) - libm.sqrt(12345.6789)) < 1e-10}\")\n",
        "else:\n",
        "    print(\"libm not found on this system\")\n",
        "\n",
        "# â”€â”€ Simulate what a Cython speedup would look like â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def mean_python(values: list) -> float:\n",
        "    \"\"\"Pure Python mean â€” bytecode loop.\"\"\"\n",
        "    n = len(values)\n",
        "    if n == 0: return 0.0\n",
        "    total = 0.0\n",
        "    for v in values:\n",
        "        total += v\n",
        "    return total / n\n",
        "\n",
        "\n",
        "def mean_builtin(values: list) -> float:\n",
        "    \"\"\"Using C-level builtins â€” effectively a C extension internally.\"\"\"\n",
        "    return sum(values) / len(values)\n",
        "\n",
        "\n",
        "data = list(range(100_000))\n",
        "\n",
        "t_py  = timeit.timeit(lambda: mean_python(data),  number=20)\n",
        "t_c   = timeit.timeit(lambda: mean_builtin(data), number=20)\n",
        "print(f\"\\nmean_python:  {t_py:.3f}s\")\n",
        "print(f\"mean_builtin: {t_c:.3f}s  ({t_py/t_c:.1f}x faster â€” built-in sum() is a C extension!)\")\n",
        "\n",
        "# â”€â”€ Cython source (shown as text â€” requires build step) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "cython_source = '''\n",
        "# fast_stats.pyx â€” compile with: python setup.py build_ext --inplace\n",
        "\n",
        "def mean_cython(list values):\n",
        "    cdef int    n     = len(values)\n",
        "    if n == 0: return 0.0\n",
        "    cdef double total = 0.0\n",
        "    cdef double v\n",
        "    for v in values:\n",
        "        total += v\n",
        "    return total / n\n",
        "'''\n",
        "print(\"\\n--- Cython source (requires compilation) ---\")\n",
        "print(cython_source)\n"
      ],
      "id": "4fMC_AIUGV96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KEHXruFGV96"
      },
      "source": [
        "---\n",
        "## ğŸ–¥ï¸ Topic 20: Bytecode & Python VM\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "_KEHXruFGV96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWIBUoLVGV96"
      },
      "source": [
        "### What is it?\n",
        "Python source is compiled to **bytecode** â€” a platform-independent instruction set\n",
        "executed by the CPython virtual machine (`ceval.c`).\n",
        "\n",
        "```\n",
        "source.py â”€â”€â–º compile â”€â”€â–º __pycache__/source.cpython-3xx.pyc â”€â”€â–º CPython VM executes\n",
        "```\n",
        "\n",
        "### Why it matters\n",
        "- Explains performance differences between code patterns\n",
        "- Local variables are array-indexed (fast); globals require dictionary lookup (slow)\n",
        "- List comprehensions generate bytecode without `STORE_NAME` overhead of explicit loops\n",
        "- Tools like `dis`, `py_compile`, Nuitka, PyInstaller, py2exe all work at this level\n"
      ],
      "id": "tWIBUoLVGV96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "8rad1PMwGV97"
      },
      "outputs": [],
      "source": [
        "import dis, timeit\n",
        "\n",
        "# â”€â”€ Disassemble a function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def add_numbers(a, b):\n",
        "    result = a + b\n",
        "    return result\n",
        "\n",
        "print(\"=== Bytecode for add_numbers ===\")\n",
        "dis.dis(add_numbers)\n",
        "\n",
        "# â”€â”€ Compare bytecode: loop vs list comprehension â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def squares_loop(n):\n",
        "    result = []\n",
        "    for i in range(n):\n",
        "        result.append(i * i)\n",
        "    return result\n",
        "\n",
        "def squares_comp(n):\n",
        "    return [i * i for i in range(n)]\n",
        "\n",
        "print(\"\\n=== Loop version ===\")\n",
        "dis.dis(squares_loop)\n",
        "\n",
        "print(\"\\n=== List comprehension (more efficient bytecode) ===\")\n",
        "dis.dis(squares_comp)\n",
        "\n",
        "N = 10_000\n",
        "t_loop = timeit.timeit(lambda: squares_loop(N), number=500)\n",
        "t_comp = timeit.timeit(lambda: squares_comp(N), number=500)\n",
        "print(f\"\\nLoop:        {t_loop:.3f}s\")\n",
        "print(f\"Comprehension: {t_comp:.3f}s  ({t_loop/t_comp:.2f}x faster)\")\n"
      ],
      "id": "8rad1PMwGV97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Xvd1ymT-GV97"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Global vs local variable lookup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import timeit\n",
        "\n",
        "GLOBAL_RANGE = range   # global lookup is a dict lookup each time\n",
        "\n",
        "def sum_global(n):\n",
        "    total = 0\n",
        "    for i in range(n):     # 'range' looked up in globals dict every iteration\n",
        "        total += i\n",
        "    return total\n",
        "\n",
        "def sum_local(n):\n",
        "    total = 0\n",
        "    _range = range         # hoist global to local slot (array index â€” O(1))\n",
        "    for i in _range(n):\n",
        "        total += i\n",
        "    return total\n",
        "\n",
        "N = 1_000_000\n",
        "t_g = timeit.timeit(lambda: sum_global(N), number=5)\n",
        "t_l = timeit.timeit(lambda: sum_local(N),  number=5)\n",
        "print(f\"Global lookup: {t_g:.3f}s\")\n",
        "print(f\"Local  lookup: {t_l:.3f}s  ({t_g/t_l:.2f}x faster)\")\n",
        "\n",
        "# â”€â”€ Inspect .pyc cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import py_compile, marshal, importlib.util, tempfile, os\n",
        "\n",
        "with tempfile.NamedTemporaryFile(suffix='.py', delete=False, mode='w') as f:\n",
        "    f.write(\"def hello(): return 'world'\\n\")\n",
        "    py_path = f.name\n",
        "\n",
        "pyc_path = py_compile.compile(py_path, cfile=py_path + 'c')\n",
        "size_py  = os.path.getsize(py_path)\n",
        "size_pyc = os.path.getsize(pyc_path)\n",
        "print(f\"\\n.py  size: {size_py} bytes\")\n",
        "print(f\".pyc size: {size_pyc} bytes  (includes magic number, timestamp, size, marshalled code)\")\n",
        "\n",
        "os.unlink(py_path)\n",
        "os.unlink(pyc_path)\n"
      ],
      "id": "Xvd1ymT-GV97"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1E_9q3PGV97"
      },
      "source": [
        "---\n",
        "## ğŸ“Š Topic 21: Profiling & Performance Optimization\n",
        "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n"
      ],
      "id": "l1E_9q3PGV97"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPVKgDtGV97"
      },
      "source": [
        "### What is it?\n",
        "**Optimization without profiling is guesswork.**\n",
        "Python provides multiple profiling tools:\n",
        "\n",
        "| Tool | What it measures | Overhead |\n",
        "|------|-----------------|----------|\n",
        "| `cProfile` | Function call counts & time | Low |\n",
        "| `tracemalloc` | Memory allocations by line | Medium |\n",
        "| `timeit` | Micro-benchmark a snippet | Minimal |\n",
        "| `line_profiler` | Line-by-line timing | High (dev only) |\n",
        "| `py-spy` | Sampling profiler (no code change) | Very low |\n",
        "\n",
        "### The workflow\n",
        "```\n",
        "1. Measure (cProfile)  â†’  2. Find hotspot  â†’  3. Benchmark change (timeit)\n",
        "â†’  4. Apply fix  â†’  5. Verify speedup  â†’  repeat\n",
        "```\n"
      ],
      "id": "HXPVKgDtGV97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "C5cc-0nXGV97"
      },
      "outputs": [],
      "source": [
        "import cProfile, pstats, io, tracemalloc, functools, timeit\n",
        "\n",
        "# â”€â”€ 1. cProfile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def slow_process(n):\n",
        "    \"\"\"Deliberately inefficient â€” uses list for membership test.\"\"\"\n",
        "    data = list(range(n))\n",
        "    return sum(x for x in data if x in data[: n // 2])   # O(nÂ²)\n",
        "\n",
        "def profile_func(func, *args, top_n=8):\n",
        "    pr = cProfile.Profile()\n",
        "    pr.enable()\n",
        "    result = func(*args)\n",
        "    pr.disable()\n",
        "    buf = io.StringIO()\n",
        "    pstats.Stats(pr, stream=buf).sort_stats('cumulative').print_stats(top_n)\n",
        "    print(buf.getvalue())\n",
        "    return result\n",
        "\n",
        "print(\"=== cProfile output ===\")\n",
        "profile_func(slow_process, 5_000)\n",
        "\n",
        "\n",
        "# â”€â”€ 2. tracemalloc â€” memory by line â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "tracemalloc.start()\n",
        "\n",
        "def allocate_lots():\n",
        "    return {i: [j**2 for j in range(100)] for i in range(500)}\n",
        "\n",
        "data = allocate_lots()\n",
        "snap = tracemalloc.take_snapshot()\n",
        "print(\"\\n=== Top memory lines (tracemalloc) ===\")\n",
        "for stat in snap.statistics('lineno')[:3]:\n",
        "    print(f\"  {stat}\")\n",
        "tracemalloc.stop()\n",
        "del data\n"
      ],
      "id": "C5cc-0nXGV97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "Zf6Wvd-7GV98"
      },
      "outputs": [],
      "source": [
        "import timeit, functools\n",
        "\n",
        "# â”€â”€ 3. Key optimization patterns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "print(\"=== Pattern A: set vs list for membership ===\")\n",
        "N    = 100_000\n",
        "lst  = list(range(N))\n",
        "st   = set(lst)\n",
        "\n",
        "t_list = timeit.timeit(lambda: N-1 in lst, number=10_000)\n",
        "t_set  = timeit.timeit(lambda: N-1 in st,  number=10_000)\n",
        "print(f\"  list O(n): {t_list*1000:.2f}ms\")\n",
        "print(f\"  set  O(1): {t_set*1000:.4f}ms  ({t_list/t_set:.0f}x faster)\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Pattern B: lru_cache for pure functions ===\")\n",
        "def fib_slow(n):\n",
        "    if n < 2: return n\n",
        "    return fib_slow(n-1) + fib_slow(n-2)\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def fib_fast(n):\n",
        "    if n < 2: return n\n",
        "    return fib_fast(n-1) + fib_fast(n-2)\n",
        "\n",
        "t_slow = timeit.timeit(lambda: fib_slow(25), number=10)\n",
        "t_fast = timeit.timeit(lambda: fib_fast(25), number=10)\n",
        "print(f\"  Without cache: {t_slow:.4f}s\")\n",
        "print(f\"  With cache:    {t_fast:.6f}s  ({t_slow/t_fast:.0f}x faster)\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Pattern C: str.join vs concatenation ===\")\n",
        "words = ['hello'] * 1000\n",
        "t_concat = timeit.timeit(lambda: ''.join(['x' + w for w in words]), number=1000)\n",
        "t_join   = timeit.timeit(lambda: ' '.join(words), number=1000)\n",
        "print(f\"  concat loop: {t_concat*1000:.2f}ms\")\n",
        "print(f\"  str.join:    {t_join*1000:.3f}ms  ({t_concat/t_join:.1f}x faster)\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Pattern D: list comprehension vs map+lambda ===\")\n",
        "data = list(range(10_000))\n",
        "t_map  = timeit.timeit(lambda: list(map(lambda x: x*2, data)), number=1000)\n",
        "t_comp = timeit.timeit(lambda: [x*2 for x in data],            number=1000)\n",
        "print(f\"  map+lambda:  {t_map*1000:.2f}ms\")\n",
        "print(f\"  list comp:   {t_comp*1000:.2f}ms  ({t_map/t_comp:.2f}x faster)\")\n",
        "\n",
        "print(\"\\nâœ… Golden Rule: Measure â†’ Find â†’ Fix â†’ Verify â†’ Repeat\")\n"
      ],
      "id": "Zf6Wvd-7GV98"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_B2l9sMGV98"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ Summary & Quick Reference\n",
        "\n",
        "| Topic | Key Takeaway | Best Use Case |\n",
        "|-------|-------------|---------------|\n",
        "| **Metaclasses** | Class of a class; intercepts class creation | Auto-registration, ORM field discovery |\n",
        "| **Descriptors** | Reusable attribute logic via `__get__`/`__set__` | Validated fields, computed properties |\n",
        "| **Context Managers** | Guaranteed setup/teardown via `with` | DB transactions, file locking |\n",
        "| **Decorators** | Wrap functions without modifying them | Retry, caching, auth, logging |\n",
        "| **Generators** | Lazy evaluation, O(1) memory pipelines | Streaming ETL, large datasets |\n",
        "| **Asyncio** | Cooperative concurrency for I/O | High-concurrency servers, scrapers |\n",
        "| **Multithreading** | I/O overlap in same process | Parallel downloads, background tasks |\n",
        "| **Multiprocessing** | True CPU parallelism, no GIL | Batch computation, ML preprocessing |\n",
        "| **GIL** | Only one thread runs Python at a time | Explains why threads â‰  speedup for CPU |\n",
        "| **Memory / GC** | Refcounting + cyclic GC | Long-running services, leak detection |\n",
        "| **Weak References** | Hold ref without preventing GC | Caches, observer patterns |\n",
        "| **`__slots__`** | Replace `__dict__` with fixed array | High-volume objects, tight memory |\n",
        "| **ABC** | Enforce interface contracts | Plugin systems, adapters |\n",
        "| **Monkey Patching** | Replace attrs at runtime | Testing mocks, instrumentation |\n",
        "| **Closures** | Capture enclosing scope | Factory functions, stateful callbacks |\n",
        "| **Introspection** | Examine types/attrs/signatures at runtime | Frameworks, CLI generators |\n",
        "| **Dynamic Attrs** | `__getattr__` for missing attrs | ORM lazy-loading, proxies |\n",
        "| **Dunder Methods** | Participate in Python syntax | Domain types, DSLs |\n",
        "| **C Extensions** | Compiled code, bypass GIL | Hotspot optimisation, wrappers |\n",
        "| **Bytecode** | What CPython actually executes | Performance analysis, tooling |\n",
        "| **Profiling** | Measure before optimising | Every performance task |\n",
        "\n",
        "---\n",
        "*Generated for Google Colab Â· All examples use Python stdlib only Â· No pip installs required*\n"
      ],
      "id": "a_B2l9sMGV98"
    }
  ]
}